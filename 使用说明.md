# 大规模SAR图像多类别有向目标检测系统使用说明

## 1. 项目概述

本系统是一个基于深度学习的SAR图像多类别有向目标检测系统，能够自动识别和定位SAR图像中的多种目标，并输出带有旋转角度的边界框。系统结合了CNN和Transformer的优势，特别优化了SAR图像的特性，能够有效处理相干斑噪声、低对比度和目标方向变化等挑战。

主要应用场景包括：
- 遥感图像分析
- 海洋监测
- 军事侦察
- 灾害评估
- 基础设施监控

## 2. 快速开始

系统提供了`quick_start.py`脚本，帮助您快速上手整个项目。该脚本集成了安装依赖、准备示例数据、训练小型模型和推理演示等功能。

### 2.1 安装依赖

```bash
python quick_start.py install
```

此命令会检查Python版本并安装`requirements.txt`中列出的所有依赖包。

### 2.2 准备示例数据集

```bash
python quick_start.py prepare
```

此命令会创建一个示例数据集，包含10张训练图像和3张验证图像，以及相应的COCO格式标注文件。示例数据集会保存在`dataset`目录下。

### 2.3 快速训练模型

```bash
python quick_start.py train
```

此命令会使用示例数据集快速训练一个小型模型，结果保存在`quick_output`目录下。训练过程中会自动调整参数以加快训练速度。

### 2.4 推理演示

```bash
python quick_start.py inference
```

此命令会使用训练好的模型进行推理演示，并生成可视化结果。

### 2.5 一键完成所有步骤

```bash
python quick_start.py all
```

此命令会依次执行上述所有步骤，从安装依赖到推理演示。

## 3. 环境配置

### 3.1 基本环境要求

- Python 3.7+ 
- PyTorch 1.8+ 
- CUDA 10.2+（如需GPU加速）

### 3.2 安装依赖

使用以下命令安装项目所需的依赖包：

```bash
pip install -r requirements.txt
```

依赖包列表：
- torch
- torchvision
- opencv-python
- numpy
- matplotlib
- scikit-image
- scikit-learn
- pycocotools
- tqdm
- addict
- yacs
- pillow
- thop

### 3.3 验证环境

安装完成后，可以通过以下方式验证环境是否配置正确：

```python
import torch
print(f"PyTorch版本: {torch.__version__}")
print(f"CUDA可用: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA版本: {torch.version.cuda}")
    print(f"GPU数量: {torch.cuda.device_count()}")
```

## 4. 数据集准备

### 4.1 数据集结构

本系统支持自定义SAR图像数据集，数据集的组织结构如下：

```
dataset/
├── images/                # 图像文件夹
│   ├── train/             # 训练集图像
│   ├── val/               # 验证集图像
│   └── test/              # 测试集图像
└── annotations/           # 标注文件夹
    ├── train.json         # 训练集标注文件
    ├── val.json           # 验证集标注文件
    └── test.json          # 测试集标注文件
```

### 4.2 标注格式

标注文件采用COCO格式，但需要额外添加旋转角度信息。每个边界框的格式为`[x, y, width, height, angle]`，其中：
- `x`, `y`：边界框中心点坐标
- `width`, `height`：边界框的宽度和高度
- `angle`：边界框的旋转角度（度）

COCO格式的标注文件示例：

```json
{
  "images": [
    {
      "id": 1,
      "file_name": "image_1.jpg",
      "width": 640,
      "height": 640
    }
  ],
  "annotations": [
    {
      "id": 1,
      "image_id": 1,
      "category_id": 1,
      "bbox": [320, 320, 100, 50, 45],
      "area": 5000,
      "iscrowd": 0
    }
  ],
  "categories": [
    {"id": 1, "name": "ship"},
    {"id": 2, "name": "airplane"},
    {"id": 3, "name": "vehicle"}
  ]
}
```

### 4.3 数据预处理

系统内置了多种数据预处理方法，包括：
- 强度归一化
- 自适应直方图均衡化
- 相干斑噪声增强
- 大尺度抖动
- 旋转和翻转

这些预处理方法可以在`config.py`中的`DATA_AUGMENTATION`部分进行配置。

## 5. 配置参数详解

`config.py`文件包含了系统的所有配置参数，以下是主要配置项的详细说明：

### 5.1 数据集配置

```python
# 数据集名称
config.DATASET.NAME = "SARDet-100K"
# 数据集根目录
config.DATASET.ROOT = "dataset"
# 类别名称
config.DATASET.CLASSES = ["ship", "airplane", "vehicle", "building", "other"]
# 类别数量
config.DATASET.NUM_CLASSES = len(config.DATASET.CLASSES)
# 图像尺寸
config.DATASET.IMAGE_SIZE = 640
# 批次大小
config.DATASET.BATCH_SIZE = 32
# 数据加载器工作进程数
config.DATASET.NUM_WORKERS = 4
# 训练/验证/测试集比例
config.DATASET.SPLIT_RATIO = [0.7, 0.15, 0.15]
```

### 5.2 模型配置

```python
# 模型类型
config.MODEL.TYPE = "HybridCNNTransformer"
# 输入通道数
config.MODEL.IN_CHANNELS = 1
# 骨干网络
config.MODEL.BACKBONE = "CSPDarknet"
# 颈部网络
config.MODEL.NECK = "FPN_PAN"
# 检测头
config.MODEL.HEAD = "OrientedDetectionHead"
# 是否使用预训练权重
config.MODEL.PRETRAINED = False
# 预训练模型路径
config.MODEL.PRETRAINED_PATH = ""
```

### 5.3 训练配置

```python
# 总训练轮数
config.TRAIN.EPOCHS = 300
# 初始学习率
config.TRAIN.LR = 0.001
# 学习率衰减策略
config.TRAIN.LR_SCHEDULER = "cosine"
# 权重衰减
config.TRAIN.WEIGHT_DECAY = 0.0005
# 优化器类型
config.TRAIN.OPTIMIZER = "adam"
# 动量
config.TRAIN.MOMENTUM = 0.9
# 梯度裁剪阈值
config.TRAIN.GRAD_CLIP = 35.0
# 热身训练轮数
config.TRAIN.WARMUP_EPOCHS = 5
# 验证频率
config.TRAIN.VAL_FREQ = 1
# 是否恢复训练
config.TRAIN.RESUME = False
# 恢复训练的模型路径
config.TRAIN.RESUME_PATH = ""
```

### 5.4 损失函数配置

```python
# 分类损失类型
config.LOSS.CLASS_LOSS = "FocalLoss"
# 回归损失类型
config.LOSS.REG_LOSS = "GIoULoss"
# 角度损失类型
config.LOSS.ANGLE_LOSS = "CircularLoss"
# IoU损失权重
config.LOSS.IOU_LOSS_WEIGHT = 1.0
# 分类损失权重
config.LOSS.CLASS_LOSS_WEIGHT = 1.0
# 角度损失权重
config.LOSS.ANGLE_LOSS_WEIGHT = 0.5
# Focal Loss的gamma参数
config.LOSS.FOCAL_GAMMA = 2.0
# Focal Loss的alpha参数
config.LOSS.FOCAL_ALPHA = 0.25
```

### 5.5 数据增强配置

```python
# 是否启用数据增强
config.DATA_AUGMENTATION.ENABLE = True
# 旋转增强范围(度)
config.DATA_AUGMENTATION.ROTATION_RANGE = 180
# 缩放增强范围
config.DATA_AUGMENTATION.SCALE_RANGE = [0.8, 1.2]
# 翻转概率
config.DATA_AUGMENTATION.FLIP_PROB = 0.5
# 马赛克增强概率
config.DATA_AUGMENTATION.MOSAIC_PROB = 0.5
# 大尺度抖动概率
config.DATA_AUGMENTATION.LSJ_PROB = 0.3
# 斑点噪声增强概率
config.DATA_AUGMENTATION.SPECKLE_NOISE_PROB = 0.2
# 对比度调整概率
config.DATA_AUGMENTATION.CONTRAST_ADJUST_PROB = 0.2
```

### 5.6 测试配置

```python
# 置信度阈值
config.TEST.CONFIDENCE_THRESHOLD = 0.3
# IoU阈值
config.TEST.IOU_THRESHOLD = 0.5
# 是否使用旋转NMS
config.TEST.USE_RNMS = True
# 旋转NMS阈值
config.TEST.RNMS_THRESHOLD = 0.1
# 是否使用TTA(测试时增强)
config.TEST.USE_TTA = False
# TTA缩放倍数
config.TEST.TTA_SCALES = [0.5, 1.0, 1.5]
```

### 5.7 设备配置

```python
# GPU ID列表
config.DEVICE.GPU_IDS = [0]
# 是否使用分布式训练
config.DEVICE.DISTRIBUTED = False
# 分布式训练后端
config.DEVICE.DIST_BACKEND = "nccl"
# 分布式训练端口
config.DEVICE.DIST_PORT = 29500
# 是否使用混合精度训练
config.DEVICE.MIXED_PRECISION = False
```

## 6. 训练指南

### 6.1 基本训练

使用以下命令开始基本训练：

```bash
python train.py --config config.py --output_dir output
```

参数说明：
- `--config`：配置文件路径，默认为`config.py`
- `--output_dir`：输出目录，用于保存模型和日志，默认为`output`

### 6.2 恢复训练

如果训练中断，可以使用以下命令恢复训练：

```bash
python train.py --config config.py --output_dir output --resume True --resume_path output/models/latest_model.pth
```

参数说明：
- `--resume`：是否恢复训练
- `--resume_path`：恢复训练的模型路径

### 6.3 快速演示训练

使用以下命令进行快速演示训练（使用更小的模型和更少的训练轮数）：

```bash
python train.py --config config.py --output_dir quick_output --quick_demo True
```

参数说明：
- `--quick_demo`：是否使用快速演示模式

### 6.4 分布式训练

在多GPU环境下，可以使用以下命令启动分布式训练：

```bash
python -m torch.distributed.launch --nproc_per_node=4 train.py --config config.py --output_dir output
```

参数说明：
- `--nproc_per_node`：使用的GPU数量

### 6.5 训练过程监控

训练过程中，系统会生成以下输出：
- 训练日志：保存在`output/logs/train.log`文件中
- 学习率曲线：保存在`output/plots/lr_curve.png`文件中
- 损失曲线：保存在`output/plots/loss_curve.png`文件中
- 验证指标：保存在`output/plots/metrics_curve.png`文件中

模型会定期保存到`output/models/`目录下，包括：
- 最新模型：`latest_model.pth`
- 最佳模型：`best_model.pth`

## 7. 测试与评估

### 7.1 基本测试

使用以下命令测试模型性能：

```bash
python test.py --config config.py --model_path output/models/best_model.pth --output_dir output
```

参数说明：
- `--config`：配置文件路径，默认为`config.py`
- `--model_path`：模型权重文件路径，必须指定
- `--output_dir`：输出目录，用于保存测试结果，默认为`output`

### 7.2 指定测试数据集

可以使用以下命令指定测试数据集：

```bash
python test.py --config config.py --model_path output/models/best_model.pth --output_dir output --test_data custom_test_data
```

参数说明：
- `--test_data`：测试数据集路径，覆盖配置文件中的设置

### 7.3 评估指标

测试完成后，系统会生成以下评估指标：
- **mAP (mean Average Precision)**：平均精确率
- **Precision**：精确率
- **Recall**：召回率
- **F1 Score**：F1分数
- **FPS (Frames Per Second)**：每秒处理帧数

这些指标会保存在`output/results/metrics.txt`文件中。

### 7.4 结果可视化

测试过程中，系统会生成以下可视化结果：
- 检测结果图像：保存在`output/results/visualizations/`目录下
- PR曲线：保存在`output/results/plots/pr_curve.png`文件中
- 混淆矩阵：保存在`output/results/plots/confusion_matrix.png`文件中

## 8. 推理演示

### 8.1 单张图像推理

可以使用以下代码对单张图像进行推理：

```python
import cv2
import torch
from config import Config
from model import SAROrientedDetector
import utils

# 加载配置
config = Config()

# 设置设备
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 初始化模型
model = SAROrientedDetector(
    num_classes=config.DATASET.NUM_CLASSES,
    in_channels=config.MODEL.IN_CHANNELS
)

# 加载模型权重
model.load_state_dict(torch.load('output/models/best_model.pth', map_location=device)['model_state_dict'])
model.to(device)
model.eval()

# 读取图像
image = cv2.imread('path/to/image.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# 推理
with torch.no_grad():
    detections = utils.inference_single_image(model, image, config, device)

# 可视化结果
visualized_image = utils.visualize_detections(
    image, 
    detections, 
    config.DATASET.CLASSES, 
    score_threshold=config.TEST.CONFIDENCE_THRESHOLD
)

# 显示结果
cv2.imshow('Detection Results', cv2.cvtColor(visualized_image, cv2.COLOR_RGB2BGR))
cv2.waitKey(0)
cv2.destroyAllWindows()

# 保存结果
cv2.imwrite('path/to/output.jpg', cv2.cvtColor(visualized_image, cv2.COLOR_RGB2BGR))
```

### 8.2 批量图像推理

可以使用以下代码对文件夹中的所有图像进行批量推理：

```python
import os
import cv2
import torch
from config import Config
from model import SAROrientedDetector
import utils

# 加载配置
config = Config()

# 设置设备
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 初始化模型
model = SAROrientedDetector(
    num_classes=config.DATASET.NUM_CLASSES,
    in_channels=config.MODEL.IN_CHANNELS
)

# 加载模型权重
model.load_state_dict(torch.load('output/models/best_model.pth', map_location=device)['model_state_dict'])
model.to(device)
model.eval()

# 输入和输出文件夹
input_folder = 'path/to/input/images'
output_folder = 'path/to/output/images'
os.makedirs(output_folder, exist_ok=True)

# 遍历输入文件夹中的所有图像
for image_name in os.listdir(input_folder):
    if image_name.endswith(('.jpg', '.jpeg', '.png', '.bmp')):
        # 读取图像
        image_path = os.path.join(input_folder, image_name)
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # 推理
        with torch.no_grad():
            detections = utils.inference_single_image(model, image, config, device)
        
        # 可视化结果
        visualized_image = utils.visualize_detections(
            image, 
            detections, 
            config.DATASET.CLASSES, 
            score_threshold=config.TEST.CONFIDENCE_THRESHOLD
        )
        
        # 保存结果
        output_path = os.path.join(output_folder, image_name)
        cv2.imwrite(output_path, cv2.cvtColor(visualized_image, cv2.COLOR_RGB2BGR))
        
        print(f'处理完成: {image_name}')

print('所有图像处理完成')
```

## 9. 高级功能

### 9.1 分布式训练

分布式训练可以在多GPU环境下加速训练过程。使用以下命令启动分布式训练：

```bash
python -m torch.distributed.launch --nproc_per_node=4 train.py --config config.py --output_dir output
```

在`config.py`中，需要相应地配置以下参数：

```python
# GPU ID列表
config.DEVICE.GPU_IDS = [0, 1, 2, 3]
# 是否使用分布式训练
config.DEVICE.DISTRIBUTED = True
# 分布式训练后端
config.DEVICE.DIST_BACKEND = "nccl"
# 分布式训练端口
config.DEVICE.DIST_PORT = 29500
```

### 9.2 混合精度训练

混合精度训练可以减少显存占用并提高训练速度。在`config.py`中设置：

```python
# 是否使用混合精度训练
config.DEVICE.MIXED_PRECISION = True
```

### 9.3 知识蒸馏

知识蒸馏可以将大型模型的知识转移到小型模型中。在`config.py`中设置：

```python
# 是否启用知识蒸馏
config.OPTIMIZATION.KNOWLEDGE_DISTILLATION.ENABLE = True
# 教师模型路径
config.OPTIMIZATION.KNOWLEDGE_DISTILLATION.TEACHER_MODEL_PATH = 'path/to/teacher/model.pth'
# 知识蒸馏温度参数
config.OPTIMIZATION.KNOWLEDGE_DISTILLATION.TEMPERATURE = 2.0
# 知识蒸馏权重参数
config.OPTIMIZATION.KNOWLEDGE_DISTILLATION.ALPHA = 0.5
```

### 9.4 模型剪枝

模型剪枝可以减少模型大小和推理时间。在`config.py`中设置：

```python
# 是否启用模型剪枝
config.OPTIMIZATION.PRUNING.ENABLE = True
# 剪枝比例
config.OPTIMIZATION.PRUNING.RATIO = 0.3
# 剪枝频率
config.OPTIMIZATION.PRUNING.FREQ = 10
```

### 9.5 量化

模型量化可以进一步减少模型大小和加速推理。在`config.py`中设置：

```python
# 是否启用模型量化
config.OPTIMIZATION.QUANTIZATION.ENABLE = True
# 量化类型 (dynamic/static)
config.OPTIMIZATION.QUANTIZATION.TYPE = 'dynamic'
```

### 9.6 域适应

域适应可以提高模型在不同数据集上的泛化能力。在`config.py`中设置：

```python
# 是否启用域适应
config.OPTIMIZATION.DOMAIN_ADAPTATION.ENABLE = True
# 域适应方法
config.OPTIMIZATION.DOMAIN_ADAPTATION.METHOD = 'DANN'
# 域适应损失权重
config.OPTIMIZATION.DOMAIN_ADAPTATION.LAMBDA = 0.1
```

## 10. 常见问题与解决方案

### 10.1 内存不足问题

**问题**：训练过程中出现CUDA内存不足的错误。

**解决方案**：
- 减小批量大小（`config.DATASET.BATCH_SIZE`）
- 减小图像尺寸（`config.DATASET.IMAGE_SIZE`）
- 启用混合精度训练（`config.DEVICE.MIXED_PRECISION = True`）
- 使用更小的骨干网络
- 减少数据增强的复杂度

### 10.2 训练不稳定问题

**问题**：训练过程中损失函数波动较大，或者不收敛。

**解决方案**：
- 调整学习率（`config.TRAIN.LR`）
- 使用学习率预热（`config.TRAIN.WARMUP_EPOCHS > 0`）
- 调整权重衰减（`config.TRAIN.WEIGHT_DECAY`）
- 调整损失函数权重（`config.LOSS`相关参数）
- 检查数据标注是否正确

### 10.3 测试结果不佳问题

**问题**：模型在测试集上的性能不佳。

**解决方案**：
- 增加训练轮数
- 调整数据增强策略
- 检查数据集是否存在类别不平衡问题
- 调整测试参数（如置信度阈值、IoU阈值等）
- 尝试使用测试时增强（`config.TEST.USE_TTA = True`）

### 10.4 安装依赖问题

**问题**：安装依赖包时出现错误。

**解决方案**：
- 确保pip是最新版本：`pip install --upgrade pip`
- 对于pycocotools安装失败的问题，可以尝试：`pip install pycocotools-windows`（Windows系统）或 `pip install pycocotools`（Linux系统）
- 对于特定于CUDA版本的包，可以指定版本安装，例如：`pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html`

## 11. 附录

### 11.1 项目结构

```
├── config.py              # 配置文件，包含所有超参数和设置
├── data_loader.py         # 数据加载和预处理模块
├── model.py               # 模型定义，包含骨干网络、颈部网络和检测头等
├── utils.py               # 辅助函数，包含数据处理、后处理、评估指标等
├── train.py               # 训练脚本
├── test.py                # 测试脚本
├── quick_start.py         # 快速启动脚本
├── requirements.txt       # 项目依赖
├── README.md              # 项目说明文档
└── 使用说明.md             # 详细使用说明文档
```

### 11.2 示例数据集说明

使用`quick_start.py prepare`命令生成的示例数据集包含以下内容：
- 10张训练图像
- 3张验证图像
- 3个目标类别：ship（船只）、airplane（飞机）、vehicle（车辆）
- 每张图像包含2-5个模拟目标
- 模拟目标带有随机的旋转角度
- 图像中添加了模拟的斑点噪声

### 11.3 SAR图像特性

SAR（合成孔径雷达）图像具有以下特性：
- 相干斑噪声：SAR图像固有的乘性噪声
- 低对比度：目标与背景的对比度较低
- 几何失真：由于侧视成像和地形影响，可能出现几何失真
- 目标方向变化：SAR图像中的目标可能以任意方向出现
- 多极化信息：部分SAR系统可以获取多极化图像

本系统针对这些特性进行了专门优化，能够有效处理SAR图像中的目标检测任务。

### 11.4 支持的模型架构

本系统支持以下模型架构：
- 混合CNN-Transformer架构：结合CSPDarknet和Swin Transformer的优势
- 多尺度特征融合：使用FPN-PAN结构进行高效的多尺度特征融合
- 有向目标检测：支持旋转边界框的检测和回归
- 注意力增强：集成CBAM注意力模块，提高特征表示能力

用户可以在`config.py`中的`MODEL`部分配置不同的模型组件。